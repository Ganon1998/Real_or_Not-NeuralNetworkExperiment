{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Real_or_Fake.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "h83pXhSE2KBL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a394a885-1562-47ae-d46f-489ac5dd08e2"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import sys\n",
        "import statistics\n",
        "import tensorflow as tf\n",
        "import string\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from google.colab import drive\n",
        "from tensorflow.python.framework import ops\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# NN for data augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.experimental.preprocessing.RandomWidth(0.1),\n",
        "    layers.experimental.preprocessing.RandomHeight(0.1),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.2),\n",
        "  ])\n",
        "\n",
        "d = tf.keras.models.load_model('/content/gdrive/My Drive/NewUnsupFace')\n",
        "c = tf.keras.models.load_model('/content/gdrive/My Drive/NewUnsupCNN')\n",
        "modelDen = keras.models.Sequential()\n",
        "modelCNN = keras.models.Sequential()\n",
        "\n",
        "# all of this is hard coded. Sadness.\n",
        "modelDen.add(d.layers[0])\n",
        "modelDen.add(keras.layers.Dense(16834))\n",
        "modelDen.add(keras.layers.Activation('relu'))\n",
        "modelDen.add(keras.layers.Dropout(0.6))\n",
        "modelDen.add(keras.layers.Dense(2))  # fake or real face\n",
        "modelDen.add(keras.layers.Activation('sigmoid'))\n",
        "\n",
        "\n",
        "# CNN\n",
        "modelCNN.add(c.layers[0])\n",
        "modelCNN.add(keras.layers.Flatten())\n",
        "modelCNN.add(keras.layers.Dense(16834))\n",
        "modelCNN.add(keras.layers.Activation('relu'))\n",
        "modelCNN.add(keras.layers.Dropout(0.6))\n",
        "modelCNN.add(keras.layers.Dense(2))  # fake or real face\n",
        "modelCNN.add(keras.layers.Activation('sigmoid'))\n",
        "\n",
        "x_train = []\n",
        "x_test = []\n",
        "\n",
        "y_train = []\n",
        "y_test = []\n",
        "\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "realCount = 0\n",
        "fakeCount = 0\n",
        "\n",
        "print(\"Getting real faces\")\n",
        "for filename in glob.iglob(os.path.join('/content/gdrive/My Drive/realAndFake/real_and_fake_face/training_real/', \"*.jpg\")):\n",
        "  img = cv2.imread(filename)\n",
        "  img = cv2.resize(img, (128,128))\n",
        "  img = img_to_array(img) \n",
        "  img = tf.image.rgb_to_grayscale(img)\n",
        "  x.append(img)\n",
        "  y.append([1])\n",
        "  realCount += 1\n",
        "\n",
        "\n",
        "\n",
        "print(\"Getting fake faces\")\n",
        "for filename in glob.iglob(os.path.join('/content/gdrive/My Drive/realAndFake/real_and_fake_face/training_fake/', \"*.jpg\")):\n",
        "  img = cv2.imread(filename)\n",
        "  img = cv2.resize(img, (128,128))\n",
        "  img = img_to_array(img) \n",
        "  img = tf.image.rgb_to_grayscale(img)\n",
        "  x.append(img)\n",
        "  y.append([0])\n",
        "  fakeCount += 1\n",
        "\n",
        "\n",
        "x_train = x[:1428]\n",
        "x_test = x[1428:]\n",
        "\n",
        "y_train = y[:1428]\n",
        "y_test = y[1428:]\n",
        "\n",
        "y_test = ops.convert_to_tensor(y_test, dtype=tf.float32) / 255.00\n",
        "y_train = ops.convert_to_tensor(y_train, dtype=tf.float32) / 255.00\n",
        "x_train = tf.convert_to_tensor(x_train, dtype=tf.float32) / 255.00\n",
        "x_test = tf.convert_to_tensor(x_test, dtype=tf.float32) / 255.00\n",
        "\n",
        "\n",
        "modelDen.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=keras.losses.MeanSquaredError(), metrics='accuracy')\n",
        "modelDen.fit(x=x_train, y=y_train, shuffle=True, batch_size=128, epochs=25, validation_data=(x_test, y_test))\n",
        "modelDen.save('/content/gdrive/My Drive/SavedUnSupModel')\n",
        "\n",
        "print(\"================================================\")\n",
        "print(\"================================================\")\n",
        "print(\"================================================\")\n",
        "print(\"Training CNN model now.\")\n",
        "\n",
        "modelCNN.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=keras.losses.SparseCategoricalCrossentropy(), metrics='accuracy')\n",
        "modelCNN.fit(x=x_train, y=y_train, shuffle=True, batch_size=128, epochs=25, validation_data=(x_test, y_test))\n",
        "modelCNN.save('/content/gdrive/My Drive/SavedUnSupCNN')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Getting real faces\n",
            "Getting fake faces\n",
            "Epoch 1/25\n",
            "12/12 [==============================] - 3s 183ms/step - loss: 0.2458 - accuracy: 0.2430 - val_loss: 0.2470 - val_accuracy: 1.0000\n",
            "Epoch 2/25\n",
            "12/12 [==============================] - 2s 172ms/step - loss: 0.2428 - accuracy: 0.2430 - val_loss: 0.2440 - val_accuracy: 1.0000\n",
            "Epoch 3/25\n",
            "12/12 [==============================] - 2s 168ms/step - loss: 0.2399 - accuracy: 0.2430 - val_loss: 0.2411 - val_accuracy: 1.0000\n",
            "Epoch 4/25\n",
            "12/12 [==============================] - 2s 165ms/step - loss: 0.2370 - accuracy: 0.2430 - val_loss: 0.2382 - val_accuracy: 1.0000\n",
            "Epoch 5/25\n",
            "12/12 [==============================] - 2s 168ms/step - loss: 0.2341 - accuracy: 0.2430 - val_loss: 0.2353 - val_accuracy: 1.0000\n",
            "Epoch 6/25\n",
            "12/12 [==============================] - 2s 167ms/step - loss: 0.2312 - accuracy: 0.2430 - val_loss: 0.2324 - val_accuracy: 1.0000\n",
            "Epoch 7/25\n",
            "12/12 [==============================] - 2s 166ms/step - loss: 0.2284 - accuracy: 0.2430 - val_loss: 0.2296 - val_accuracy: 1.0000\n",
            "Epoch 8/25\n",
            "12/12 [==============================] - 2s 167ms/step - loss: 0.2256 - accuracy: 0.2430 - val_loss: 0.2268 - val_accuracy: 1.0000\n",
            "Epoch 9/25\n",
            "12/12 [==============================] - 2s 166ms/step - loss: 0.2228 - accuracy: 0.2430 - val_loss: 0.2240 - val_accuracy: 1.0000\n",
            "Epoch 10/25\n",
            "12/12 [==============================] - 2s 167ms/step - loss: 0.2200 - accuracy: 0.2430 - val_loss: 0.2213 - val_accuracy: 1.0000\n",
            "Epoch 11/25\n",
            "12/12 [==============================] - 2s 166ms/step - loss: 0.2173 - accuracy: 0.2430 - val_loss: 0.2185 - val_accuracy: 1.0000\n",
            "Epoch 12/25\n",
            "12/12 [==============================] - 2s 167ms/step - loss: 0.2146 - accuracy: 0.2430 - val_loss: 0.2158 - val_accuracy: 1.0000\n",
            "Epoch 13/25\n",
            "12/12 [==============================] - 2s 168ms/step - loss: 0.2120 - accuracy: 0.2430 - val_loss: 0.2132 - val_accuracy: 1.0000\n",
            "Epoch 14/25\n",
            "12/12 [==============================] - 2s 166ms/step - loss: 0.2093 - accuracy: 0.2430 - val_loss: 0.2105 - val_accuracy: 1.0000\n",
            "Epoch 15/25\n",
            "12/12 [==============================] - 2s 166ms/step - loss: 0.2067 - accuracy: 0.2430 - val_loss: 0.2079 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "12/12 [==============================] - 2s 166ms/step - loss: 0.2041 - accuracy: 0.2430 - val_loss: 0.2054 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "12/12 [==============================] - 2s 167ms/step - loss: 0.2016 - accuracy: 0.2430 - val_loss: 0.2028 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "12/12 [==============================] - 2s 169ms/step - loss: 0.1991 - accuracy: 0.2430 - val_loss: 0.2003 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "12/12 [==============================] - 2s 165ms/step - loss: 0.1966 - accuracy: 0.2430 - val_loss: 0.1978 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "12/12 [==============================] - 2s 164ms/step - loss: 0.1941 - accuracy: 0.2430 - val_loss: 0.1953 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "12/12 [==============================] - 2s 165ms/step - loss: 0.1917 - accuracy: 0.2430 - val_loss: 0.1929 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "12/12 [==============================] - 2s 166ms/step - loss: 0.1893 - accuracy: 0.2430 - val_loss: 0.1905 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "12/12 [==============================] - 2s 167ms/step - loss: 0.1869 - accuracy: 0.2430 - val_loss: 0.1881 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "12/12 [==============================] - 2s 162ms/step - loss: 0.1845 - accuracy: 0.2430 - val_loss: 0.1857 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "12/12 [==============================] - 2s 163ms/step - loss: 0.1822 - accuracy: 0.2430 - val_loss: 0.1834 - val_accuracy: 1.0000\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/SavedUnSupModel/assets\n",
            "================================================\n",
            "================================================\n",
            "================================================\n",
            "Training CNN model now.\n",
            "Epoch 1/25\n",
            "12/12 [==============================] - 19s 2s/step - loss: 0.0795 - accuracy: 0.2248 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 2/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 0.0000e+00 - accuracy: 0.2430 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 0.0000e+00 - accuracy: 0.2430 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 4/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 0.0000e+00 - accuracy: 0.2430 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 5/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 0.0000e+00 - accuracy: 0.2430 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 6/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 0.0000e+00 - accuracy: 0.2430 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 7/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 0.0000e+00 - accuracy: 0.2430 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 8/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 0.0000e+00 - accuracy: 0.2430 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 9/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 0.0000e+00 - accuracy: 0.2430 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 10/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 0.0000e+00 - accuracy: 0.2430 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 11/25\n",
            "12/12 [==============================] - 18s 2s/step - loss: 0.0000e+00 - accuracy: 0.2430 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 12/25\n",
            "12/12 [==============================] - 18s 2s/step - loss: 0.0000e+00 - accuracy: 0.2430 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 13/25\n",
            "12/12 [==============================] - 18s 2s/step - loss: 0.0000e+00 - accuracy: 0.2430 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 14/25\n",
            "12/12 [==============================] - 18s 2s/step - loss: 0.0000e+00 - accuracy: 0.2430 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 15/25\n",
            "12/12 [==============================] - 18s 2s/step - loss: 0.0000e+00 - accuracy: 0.2430 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "12/12 [==============================] - 18s 2s/step - loss: 0.0000e+00 - accuracy: 0.2430 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 0.0000e+00 - accuracy: 0.2430 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "12/12 [==============================] - 18s 2s/step - loss: 0.0000e+00 - accuracy: 0.2430 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "12/12 [==============================] - 18s 2s/step - loss: 0.0000e+00 - accuracy: 0.2430 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "12/12 [==============================] - 18s 2s/step - loss: 0.0000e+00 - accuracy: 0.2430 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "12/12 [==============================] - 18s 2s/step - loss: 0.0000e+00 - accuracy: 0.2430 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 0.0000e+00 - accuracy: 0.2430 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 0.0000e+00 - accuracy: 0.2430 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 0.0000e+00 - accuracy: 0.2430 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "12/12 [==============================] - 18s 2s/step - loss: 0.0000e+00 - accuracy: 0.2430 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/SavedUnSupCNN/assets\n"
          ]
        }
      ]
    }
  ]
}