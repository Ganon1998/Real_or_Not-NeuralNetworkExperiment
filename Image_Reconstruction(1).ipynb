{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_Reconstruction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCP5IvUM4tGe",
        "outputId": "91e9d76c-1851-4a4b-ab78-02d405c6afb6"
      },
      "source": [
        "\n",
        "########## DATASET LICENSE INFO #############\n",
        "\n",
        "''' \n",
        "Flickr-Faces-HQ (FFHQ) is a high-quality image dataset of human faces,\n",
        "originally created as a benchmark for generative adversarial networks (GAN):\n",
        "\n",
        "    A Style-Based Generator Architecture for Generative Adversarial Networks\n",
        "    Tero Karras (NVIDIA), Samuli Laine (NVIDIA), Timo Aila (NVIDIA)\n",
        "    http://stylegan.xyz/paper\n",
        "\n",
        "The individual images were published in Flickr by their respective authors\n",
        "under either Creative Commons BY 2.0, Creative Commons BY-NC 2.0,\n",
        "Public Domain Mark 1.0, Public Domain CC0 1.0, or U.S. Government Works\n",
        "license. All of these licenses allow free use, redistribution, and adaptation\n",
        "for non-commercial purposes. However, some of them require giving appropriate\n",
        "credit to the original author, as well as indicating any changes that were\n",
        "made to the images. The license and original author of each image are\n",
        "indicated in the metadata.\n",
        "\n",
        "    https://creativecommons.org/licenses/by/2.0/\n",
        "    https://creativecommons.org/licenses/by-nc/2.0/\n",
        "    https://creativecommons.org/publicdomain/mark/1.0/\n",
        "    https://creativecommons.org/publicdomain/zero/1.0/\n",
        "    http://www.usa.gov/copyright.shtml\n",
        "\n",
        "The dataset itself (including JSON metadata, download script, and\n",
        "documentation) is made available under Creative Commons BY-NC-SA 4.0 license\n",
        "by NVIDIA Corporation. You can use, redistribute, and adapt it for\n",
        "non-commercial purposes, as long as you (a) give appropriate credit by\n",
        "citing our paper, (b) indicate any changes that you've made, and\n",
        "(c) distribute any derivative works under the same license.\n",
        "\n",
        "    https://creativecommons.org/licenses/by-nc-sa/4.0/\n",
        "'''\n",
        "\n",
        "###################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "import statistics\n",
        "import tensorflow as tf\n",
        "import string\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from google.colab import drive\n",
        "from tensorflow.python.framework import ops\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "latent_dim = 64 \n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "img_dims = (128,128,3)\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 50\n",
        "\n",
        "x_train = []\n",
        "i = 0\n",
        "directory = '/content/gdrive/My Drive/Unsupervised_Faces/'\n",
        "folder = \"000\"\n",
        "\n",
        "\n",
        "\n",
        "# there are 69 folders\n",
        "while i != 1:\n",
        "  print(\"folder \" + str(i) + \" out of 50\\n\")\n",
        "\n",
        "  if i < 10:\n",
        "    for filename in glob.iglob(os.path.join(directory + \"0\" + str(i) + folder, \"*.png\")):\n",
        "      img = cv2.imread(filename)#Image.open(filename)\n",
        "      img = cv2.resize(img, (img_dims[0],img_dims[1]))\n",
        "      img = img_to_array(img) #tf.keras.preprocessing.image.img_to_array(im)\n",
        "      img = tf.image.rgb_to_grayscale(img)\n",
        "      x_train.append(img)\n",
        "\n",
        "  else:\n",
        "    for filename in glob.iglob(os.path.join(directory +  str(i) + folder, \"*.png\")):\n",
        "      img = cv2.imread(filename)#Image.open(filename)\n",
        "      img = cv2.resize(img, (img_dims[0],img_dims[1]))\n",
        "      img = img_to_array(img) #tf.keras.preprocessing.image.img_to_array(im)\n",
        "      img = tf.image.rgb_to_grayscale(img)\n",
        "      x_train.append(img)   \n",
        "\n",
        "  i += 1\n",
        "\n",
        "print('Done!')\n",
        "\n",
        "#autoencoder = Autoencoder(latent_dim)\n",
        "\n",
        "\n",
        "X_train = np.array(x_train, dtype=\"float\") / 255.00\n",
        "X_test = np.array(x_train, dtype=\"float\") / 255.00\n",
        "X_train, X_valid = X_train[:-300], X_train[-300:]\n",
        "\n",
        "X_train = tf.convert_to_tensor(X_train, dtype=tf.int32)\n",
        "X_valid = tf.convert_to_tensor(X_valid, dtype=tf.int32)\n",
        "\n",
        "\n",
        "  # NN for data augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.experimental.preprocessing.RandomWidth(0.1),\n",
        "    layers.experimental.preprocessing.RandomHeight(0.1),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.2),\n",
        "  ])\n",
        "\n",
        "encoder = tf.keras.Sequential([\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(32, activation='relu'),\n",
        "      layers.Dropout(0.3),\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dropout(0.4),\n",
        "      layers.Dense(128, activation='relu'),\n",
        "      layers.Dropout(0.5),\n",
        "      layers.Dense(216, activation='relu'),\n",
        "    ])\n",
        "decoder = tf.keras.Sequential([\n",
        "      layers.Dense(32, activation='relu'),\n",
        "      layers.Dropout(0.2),\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dropout(0.3),\n",
        "      layers.Dense(128, activation='relu'),\n",
        "      layers.Dropout(0.4),\n",
        "      layers.Dense(216, activation='relu'),\n",
        "      layers.Dropout(0.5),\n",
        "      layers.Dense(16384, activation='sigmoid'),\n",
        "      layers.Dropout(0.6),\n",
        "      layers.Reshape((128, 128))\n",
        "    ])\n",
        "\n",
        "model = keras.models.Sequential([encoder, decoder])\n",
        "\n",
        "model.compile(optimizer='adam', loss=keras.losses.MeanSquaredError(), metric='accuracy')\n",
        "\n",
        "model.fit(X_train, X_train, epochs=20, batch_size=64, validation_data=(X_valid, X_valid))\n",
        "\n",
        "\n",
        "model.save('/content/gdrive/My Drive/Unsup_FaceFINAL')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "folder 0 out of 50\n",
            "\n",
            "folder 1 out of 50\n",
            "\n",
            "folder 2 out of 50\n",
            "\n",
            "folder 3 out of 50\n",
            "\n",
            "folder 4 out of 50\n",
            "\n",
            "folder 5 out of 50\n",
            "\n",
            "folder 6 out of 50\n",
            "\n",
            "folder 7 out of 50\n",
            "\n",
            "folder 8 out of 50\n",
            "\n",
            "folder 9 out of 50\n",
            "\n",
            "folder 10 out of 50\n",
            "\n",
            "folder 11 out of 50\n",
            "\n",
            "folder 12 out of 50\n",
            "\n",
            "folder 13 out of 50\n",
            "\n",
            "folder 14 out of 50\n",
            "\n",
            "folder 15 out of 50\n",
            "\n",
            "folder 16 out of 50\n",
            "\n",
            "folder 17 out of 50\n",
            "\n",
            "folder 18 out of 50\n",
            "\n",
            "folder 19 out of 50\n",
            "\n",
            "folder 20 out of 50\n",
            "\n",
            "folder 21 out of 50\n",
            "\n",
            "folder 22 out of 50\n",
            "\n",
            "folder 23 out of 50\n",
            "\n",
            "folder 24 out of 50\n",
            "\n",
            "folder 25 out of 50\n",
            "\n",
            "folder 26 out of 50\n",
            "\n",
            "folder 27 out of 50\n",
            "\n",
            "folder 28 out of 50\n",
            "\n",
            "folder 29 out of 50\n",
            "\n",
            "folder 30 out of 50\n",
            "\n",
            "folder 31 out of 50\n",
            "\n",
            "folder 32 out of 50\n",
            "\n",
            "folder 33 out of 50\n",
            "\n",
            "folder 34 out of 50\n",
            "\n",
            "folder 35 out of 50\n",
            "\n",
            "folder 36 out of 50\n",
            "\n",
            "folder 37 out of 50\n",
            "\n",
            "folder 38 out of 50\n",
            "\n",
            "folder 39 out of 50\n",
            "\n",
            "folder 40 out of 50\n",
            "\n",
            "folder 41 out of 50\n",
            "\n",
            "folder 42 out of 50\n",
            "\n",
            "folder 43 out of 50\n",
            "\n",
            "folder 44 out of 50\n",
            "\n",
            "folder 45 out of 50\n",
            "\n",
            "folder 46 out of 50\n",
            "\n",
            "folder 47 out of 50\n",
            "\n",
            "folder 48 out of 50\n",
            "\n",
            "folder 49 out of 50\n",
            "\n",
            "folder 50 out of 50\n",
            "\n",
            "Done!\n",
            "Epoch 1/20\n",
            "743/743 [==============================] - 37s 48ms/step - loss: 0.1757 - val_loss: 0.1168\n",
            "Epoch 2/20\n",
            "743/743 [==============================] - 35s 47ms/step - loss: 0.0828 - val_loss: 0.0571\n",
            "Epoch 3/20\n",
            "743/743 [==============================] - 35s 47ms/step - loss: 0.0422 - val_loss: 0.0307\n",
            "Epoch 4/20\n",
            "743/743 [==============================] - 35s 47ms/step - loss: 0.0236 - val_loss: 0.0179\n",
            "Epoch 5/20\n",
            "743/743 [==============================] - 35s 47ms/step - loss: 0.0141 - val_loss: 0.0110\n",
            "Epoch 6/20\n",
            "743/743 [==============================] - 35s 48ms/step - loss: 0.0089 - val_loss: 0.0071\n",
            "Epoch 7/20\n",
            "743/743 [==============================] - 35s 47ms/step - loss: 0.0058 - val_loss: 0.0047\n",
            "Epoch 8/20\n",
            "743/743 [==============================] - 35s 47ms/step - loss: 0.0038 - val_loss: 0.0031\n",
            "Epoch 9/20\n",
            "743/743 [==============================] - 38s 51ms/step - loss: 0.0026 - val_loss: 0.0022\n",
            "Epoch 10/20\n",
            "743/743 [==============================] - 35s 47ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 11/20\n",
            "743/743 [==============================] - 35s 47ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 12/20\n",
            "743/743 [==============================] - 35s 47ms/step - loss: 9.0913e-04 - val_loss: 7.6891e-04\n",
            "Epoch 13/20\n",
            "743/743 [==============================] - 35s 47ms/step - loss: 6.5993e-04 - val_loss: 5.6324e-04\n",
            "Epoch 14/20\n",
            "743/743 [==============================] - 35s 47ms/step - loss: 4.8762e-04 - val_loss: 4.2033e-04\n",
            "Epoch 15/20\n",
            "743/743 [==============================] - 35s 47ms/step - loss: 3.6736e-04 - val_loss: 3.2006e-04\n",
            "Epoch 16/20\n",
            "743/743 [==============================] - 35s 47ms/step - loss: 2.8256e-04 - val_loss: 2.4895e-04\n",
            "Epoch 17/20\n",
            "743/743 [==============================] - 36s 49ms/step - loss: 2.2209e-04 - val_loss: 1.9790e-04\n",
            "Epoch 18/20\n",
            "743/743 [==============================] - 39s 52ms/step - loss: 1.7839e-04 - val_loss: 1.6073e-04\n",
            "Epoch 19/20\n",
            "743/743 [==============================] - 36s 48ms/step - loss: 1.4633e-04 - val_loss: 1.3323e-04\n",
            "Epoch 20/20\n",
            "743/743 [==============================] - 36s 48ms/step - loss: 1.2242e-04 - val_loss: 1.1253e-04\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/Unsup_Face50000/assets\n"
          ]
        }
      ]
    }
  ]
}